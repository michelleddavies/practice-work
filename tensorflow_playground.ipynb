{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "741c1fbd-68ad-4566-8925-962db7f8a15c",
   "metadata": {},
   "source": [
    "# TensorFlow Playground\n",
    "## January 2023\n",
    "### by Michelle (Chelle) Davies\n",
    "This notebook is my environment to practive using TensorFlow's features. Eventually, I will build more specific projects. For now, there's no (intentional) cohesive narrative with these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6cf668-609c-4e57-8a49-b2772da3002e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14912\\556268602.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TensorFlow version:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopencv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "import opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90935bf5-ef3b-482b-9971-c6f1913b706b",
   "metadata": {},
   "source": [
    "## Starting with a tutorial on the basics\n",
    "Source: https://www.tensorflow.org/tutorials/quickstart/beginner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d8db8-9f67-42a4-8dfe-a31aeb7be2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the preloaded dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9040bfe6-4ff3-4677-8a64-5d351411bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e69ff9-17a9-406b-9fb8-1ea947cc5495",
   "metadata": {},
   "source": [
    "Next, I'm going to build a model. These are the options:\n",
    "1. Keras Sequential Model\n",
    "2. Keras Functional API\n",
    "\n",
    "I'm building a `tf.keras.Sequential` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974324f-53e8-4c40-83d8-122930701ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a tf.keras.Sequential model:\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa613cb9-0035-407d-8b0a-5550cd6e31b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e18de-f523-4d32-9ae6-7c03e352d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tf.nn.softmax function converts these logits to probabilities for each class:\n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa4d50d-e4da-4420-a521-c05419597498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function for training using losses.SparseCategoricalCrossentropy:\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ae6f1-fef2-4b8f-a3fd-58fbabd7873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7856630-a8e7-42c1-a043-09c25b844edc",
   "metadata": {},
   "source": [
    "Before training, configure and compile the model using Keras `Model.compile`. Set the optimizer class to adam, set the loss to the `loss_fn` function defined earlier, and specify a metric to be evaluated for the model by setting the metrics parameter to accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4039b-ef12-4b85-83bb-548efdbfb066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a8b3a-0f54-45ca-9bb1-017b0ce9a039",
   "metadata": {},
   "source": [
    "### Train and evaluate the model\n",
    "Use the Model.fit method to adjust the model parameters and minimize the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244dbff5-7679-4a1d-b489-f6b9674ef911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75023d74-4626-4313-a3f5-fdd28576ec14",
   "metadata": {},
   "source": [
    "The `Model.evaluate` method checks the model's performance, usually on a validation set or test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e1f5c-0a49-415a-b664-c8d2751021b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da7cef5-11a5-4325-bf6a-8a8b50b23642",
   "metadata": {},
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the TensorFlow tutorials.\n",
    "\n",
    "If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93596852-d1a4-49f5-a8ca-d6ded972248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5c3ddb-7349-4c9d-a4e5-6ef16b738a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751328c-9637-4637-b06c-13ff8ca1100d",
   "metadata": {},
   "source": [
    "## My Own Experiment - OCR\n",
    "Now, I'm going to make a project with my own data and exploration. I am going to explore creating OCR models with Tensorflow and Keras.\n",
    "\n",
    "*Optical character recognition or optical character reader is the electronic or mechanical conversion of images of typed, handwritten or printed text into machine-encoded text, whether from a scanned document, a photo of a document, a scene-photo or from subtitle text superimposed on an image.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef50b5-6a68-4ed3-a2aa-b0d5dc6b423d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c21c3c-3cde-45b4-b30f-c04a163a5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_dataset():\n",
    "  # load data from tensorflow framework\n",
    "  ((trainData, trainLabels), (testData, testLabels)) = mnist.load_data() \n",
    "  # Stacking train data and test data to form single array named data\n",
    "  data = np.vstack([trainData, testData]) \n",
    "  # Vertical stacking labels of train and test set\n",
    "  labels = np.hstack([trainLabels, testLabels]) \n",
    "  # return a 2-tuple of the MNIST data and labels\n",
    "  return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c7e79-29bb-49d0-bc6f-585a512eff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_az_dataset(datasetPath):\n",
    "    # List for storing data\n",
    "    data = []\n",
    "    # List for storing labels\n",
    "    labels = []\n",
    "    for row in open(datasetPath): #Openfile and start reading each row\n",
    "        #Split the row at every comma\n",
    "        row = row.split(\",\")\n",
    "        #row[0] contains label\n",
    "        label = int(row[0])\n",
    "        #Other all collumns contains pixel values make a saperate array for that\n",
    "        image = np.array([int(x) for x in row[1:]], dtype=\"uint8\")\n",
    "        #Reshaping image to 28 x 28 pixels\n",
    "        image = image.reshape((28, 28))\n",
    "        #append image to data\n",
    "        data.append(image)\n",
    "        #append label to labels\n",
    "        labels.append(label)\n",
    "    #Converting data to numpy array of type float32\n",
    "    data = np.array(data, dtype='float32')\n",
    "    #Converting labels to type int\n",
    "    labels = np.array(labels, dtype=\"int\")\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287aa429-84f5-4540-bca7-14409a0b114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(digitsData, digitsLabels) = load_mnist_dataset()\n",
    "(azData, azLabels) = load_az_dataset('hwData/A_Z Handwritten Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa639e-2665-4f16-a032-7af4065506a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the MNIST dataset occupies the labels 0-9, so let's add 10 to every A-Z label to ensure the A-Z characters are not incorrectly labeled \n",
    "azLabels += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca5f6f-0ce7-4534-bf3b-89f7e204eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the A-Z data and labels with the MNIST digits data and labels\n",
    "data = np.vstack([azData, digitsData])\n",
    "labels = np.hstack([azLabels, digitsLabels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02f736-290f-45ff-82b8-3f090161eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image in the A-Z and MNIST digts datasets are 28x28 pixels;\n",
    "# However, the architecture we're using is designed for 32x32 images,\n",
    "# So we need to resize them to 32x32\n",
    "data = [cv2.resize(image, (32, 32)) for image in data]\n",
    "data = np.array(data, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3645beb-09c3-46d2-bddc-c642afe8446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a channel dimension to every image in the dataset and scale the\n",
    "# pixel intensities of the images from [0, 255] down to [0, 1]\n",
    "data = np.expand_dims(data, axis=-1)\n",
    "data /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb6db2-4cec-43a8-bbfc-8fb7c3eef533",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelBinarizer()\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd525b36-e4c0-43fc-a63d-a22811cf80e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca66e1-db18-4793-9a95-bcb0079dcc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for skew in the labeled data\n",
    "classTotals = labels.sum(axis=0)\n",
    "classWeight = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50f4cc-6112-4363-973e-8630cf3efbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all classes and calculate the class weight\n",
    "for i in range(0, len(classTotals)):\n",
    "    classWeight[i] = classTotals.max() / classTotals[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c36c10c-10a5-4f63-8519-950e7b832d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "rotation_range=10,\n",
    "zoom_range=0.05,\n",
    "width_shift_range=0.1,\n",
    "height_shift_range=0.1,\n",
    "shear_range=0.15,\n",
    "horizontal_flip=False,\n",
    "fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c085a6e-bde7-43d5-94a4-56a7c1cfe969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import AveragePooling2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import add\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5636ee64-fda8-4fcf-911a-c9e7d8e4e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet class\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
